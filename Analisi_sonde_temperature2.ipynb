{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f70e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31025e1f",
   "metadata": {},
   "source": [
    "## Funzione per trasformare i dati in CSV\n",
    "Lo script prende in input un file .txt con il parametro 'rb' quindi in lettura in formato bytecode che vuol dire che dovrà essere decodificato.\n",
    "Per prima cosa si scorre fino alla riga che inizia con 'NR' perché i dati iniziano da li, quando la trovo imposto flag_data a 1 che serve a dirmi che da li in poi dovrò salvare le righe.\n",
    "Cerco la prima riga che inizia con '0' e la salto settando firsr_row a 1.\n",
    "Quando sia data_flag che first_row sono a 1 allora inizio a salvare le righe.\n",
    "\n",
    "Per salvare le righe:\n",
    "* prima le decodifico con .decode()\n",
    "* poi le divido con .split() che se usato senza parametri splitta la stringa in base agli spazi\n",
    "* unisco i valori delle ultime due colonne perché fanno entrambi riferimento alla data\n",
    "* elimino l'ultima riga perché l'ho unita alla penultima\n",
    "* faccio un append della riga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fd50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_csv(filename, filedest):\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(filedest + '.csv'):\n",
    "        os.remove(filedest + '.csv')\n",
    "        \n",
    "    file1 = open(filename + '.txt', \"rb\")\n",
    "    file_csv = open(filedest + '.csv', 'w+', newline ='')\n",
    "\n",
    "    count = 0\n",
    "    flag_data = 0\n",
    "\n",
    "    with file_csv:\n",
    "        for line in file1:\n",
    "\n",
    "            if b'\\xb0C' in line:     # se trovo il carattere °C lo ignoro\n",
    "                pass\n",
    "            else:\n",
    "                line = line.decode() # altrimenti decodifico la riga\n",
    "\n",
    "                # cerco la riga con i nomi della tabella\n",
    "                if line.startswith('NR'):\n",
    "                    flag_data = 1                  # quando trovo i nomi delle colonne imposto flag_data = 1\n",
    "                    table_names = line.split()     # divido i nomi delle colonne      \n",
    "                    table_names.remove('LastLine') # elimino 'LastLine' che fa riferimento ad un singolo dato duplicato\n",
    "                    #for item in table_names: print(item)\n",
    "                    write = csv.writer(file_csv)  \n",
    "                    write.writerow(table_names)\n",
    "                    #print(table_names)\n",
    "\n",
    "                # Se sono arrivato alla tabella ma la riga inizia con 0 la salto\n",
    "                elif flag_data == 1 and line.startswith('0'):\n",
    "                    pass\n",
    "\n",
    "                # Se sono arrivato alla tabella (flag_data == 1) e non sono alla prima riga\n",
    "                # inizio a salvare i dati\n",
    "                elif flag_data == 1:\n",
    "                    row = line.split()\n",
    "\n",
    "                    if not line.startswith('[END]') and len(row) == len(table_names)+1: # le righe con meno di 25 elementi hanno dati mancanti\n",
    "                        row[-2] = str(row[-2]) + ' ' + str(row[-1]) # unisco l'ora col giorno\n",
    "                        del row[-1] # elimino la colonna con i giorni\n",
    "                        write = csv.writer(file_csv)\n",
    "                        write.writerow(row)\n",
    "                        count = count+1      # aggiorno il contatore delle righe\n",
    "\n",
    "    #print(str(count) + ' righe salvate.')\n",
    "\n",
    "#txt_to_csv(filename = 'table/DiagnosisTabl',\n",
    "#           filedest = 'table/csv/DiagnosisTabl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119bcc15",
   "metadata": {},
   "source": [
    "Per convertire tutti i file da txt a csv mi basta iterare all'interno della cartella e passare ogni file alla funzione txt_to_csv che prende in input il nome del file da convertire e il percorso di destinazione del file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164fa429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogPostTHS3\n",
      "TabLogPostTHS4\n",
      "DiagnosisTabl2\n",
      "TabLogFMS2_SX\n",
      "TabLogFMS3_SX\n",
      "TabLogAntTHS4\n",
      "DiagnTableBasaments4\n",
      "DiagnosisTabl3\n",
      "DiagnosisTable\n",
      "TabLogFMS3_DX\n",
      "DiagnosisTable4\n",
      "TabLogPostTHS\n",
      "TabLogFMS2_DX\n",
      "DiagnosisTabl4\n",
      "DiagnTableBasaments\n",
      "TabLogFMS4_SX\n",
      "TabLogAntTHS\n",
      "TabLogAntTHS2\n",
      "DiagnosisTable3\n",
      "DiagnTableBasaments3\n",
      "TabLogPostTHS2\n",
      "TabLogFMS_DX\n",
      "TabLogFMS4_DX\n",
      "LONG_TERM_TEMP\n",
      "TabLogFMS_SX\n",
      "DiagnTableBasaments2\n",
      "DiagnosisTable2\n",
      "TabLogAntTHS3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# controllo se la cartella 'csv' è presente. Se c'è la elimino e la ricreo, se non c'è la creo.\n",
    "if os.path.isdir('table/csv'):\n",
    "    shutil.rmtree('table/csv')\n",
    "    os.mkdir('table/csv')\n",
    "else:\n",
    "    os.mkdir('table/csv')\n",
    "\n",
    "for filename in os.listdir('table/'):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        print(filename[:-4])\n",
    "        txt_to_csv(filename = 'table/' + filename[:-4],\n",
    "                   filedest = 'table/csv/' + filename[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9d424",
   "metadata": {},
   "source": [
    "## Funzione per caricare il CSV in un DataFrame\n",
    "La funzione prende in input il nome del file .csv da caricare, converte la colonna DataTime in datetime e la imposta come indice del dataframe. Controlla se il dataframe è ordinato e se non lo è lo riordina. Elimina la colonna NR. Restituisce il dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21abaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    #column_subset = ['t_Mach',   't_HydrTa', 't_TTlubr', 't_TT_ab1', \n",
    "                     #'t_TT_ab2', 't_HdStUp', 't_HdStLw', 't_Sfrnt1', \n",
    "                     #'t_Sfrnt2', 't_Srear',  't_Smotor', 'DataTime']\n",
    "\n",
    "    df = pd.read_csv (file,\n",
    "                      #usecols=column_subset,\n",
    "                      index_col=False)\n",
    "\n",
    "    df['DataTime'] = pd.to_datetime(df['DataTime'], format='%H:%M:%S %d.%m.%Y')\n",
    "    \n",
    "    df.set_index('DataTime', drop = True, inplace=True)\n",
    "    \n",
    "    if not df.index.is_monotonic:\n",
    "        df.sort_index(inplace = True)\n",
    "    \n",
    "    df.drop('NR', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906ac5c",
   "metadata": {},
   "source": [
    "## Processo per caricare tutti i file dello stesso tipo e salvarli come unico csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9243d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_csv(path_folder, tab_name):\n",
    "    data_list=[]\n",
    "\n",
    "    for filename in os.listdir(path_folder):\n",
    "        if tab_name in filename: \n",
    "            data = load_data(path_folder + 'csv/' + filename[:-4] + '.csv')\n",
    "            data_list.append(data)\n",
    "\n",
    "    data_all = pd.concat(data_list)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv(path_folder + '/csv/' + tab_name + '_all.csv')\n",
    "\n",
    "\n",
    "create_single_csv('table/', 'DX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086847fa",
   "metadata": {},
   "source": [
    " * Faccio una lista con tutti i nomi dei file ma senza il numero progressivo alla fine\n",
    " * Per ogni nome in lista cerco le tabelle con quel nome e le riunisco creando un unico file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28606adf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:   2%|▎         | 1/40 [00:00<00:07,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogPostTHS3\n",
      "TabLogPostTHS4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  12%|█▎        | 5/40 [00:00<00:03, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnosisTabl2\n",
      "TabLogFMS2_SX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converto .txt in .csv\t:  18%|█▊        | 7/40 [00:00<00:04,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogFMS3_SX\n",
      "TabLogAntTHS4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  22%|██▎       | 9/40 [00:01<00:04,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnTableBasaments4\n",
      "DiagnosisTabl3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converto .txt in .csv\t:  25%|██▌       | 10/40 [00:01<00:05,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnosisTable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  35%|███▌      | 14/40 [00:02<00:03,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogFMS3_DX\n",
      "DiagnosisTable4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  40%|████      | 16/40 [00:02<00:03,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogPostTHS\n",
      "TabLogFMS2_DX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converto .txt in .csv\t:  45%|████▌     | 18/40 [00:02<00:02,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnosisTabl4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  50%|█████     | 20/40 [00:03<00:03,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnTableBasaments\n",
      "TabLogFMS4_SX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  60%|██████    | 24/40 [00:03<00:01,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogAntTHS\n",
      "TabLogAntTHS2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  65%|██████▌   | 26/40 [00:03<00:01,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnosisTable3\n",
      "DiagnTableBasaments3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  70%|███████   | 28/40 [00:04<00:01,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogPostTHS2\n",
      "TabLogFMS_DX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converto .txt in .csv\t:  72%|███████▎  | 29/40 [00:04<00:01,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogFMS4_DX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converto .txt in .csv\t:  75%|███████▌  | 30/40 [00:04<00:01,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG_TERM_TEMP\n",
      "TabLogFMS_SX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t:  88%|████████▊ | 35/40 [00:05<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagnTableBasaments2\n",
      "DiagnosisTable2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "converto .txt in .csv\t:  90%|█████████ | 36/40 [00:05<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogAntTHS3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converto .txt in .csv\t: 100%|██████████| 40/40 [00:05<00:00,  7.25it/s]\n",
      "unisco le tabelle\t: 100%|██████████| 13/13 [00:09<00:00,  1.42it/s]\n",
      "elimino tab divise\t: 100%|██████████| 41/41 [00:00<00:00, 2947.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TabLogFMS2_SX', 'TabLogFMS3_SX', 'DiagnosisTable', 'TabLogFMS3_DX', 'TabLogPostTHS', 'TabLogFMS2_DX', 'DiagnTableBasaments', 'TabLogFMS4_SX', 'TabLogAntTHS', 'TabLogFMS_DX', 'TabLogFMS4_DX', 'LONG_TERM_TEMP', 'TabLogFMS_SX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# controllo se la cartella 'csv' è presente. Se c'è la elimino e la ricreo, se non c'è la creo.\n",
    "if os.path.isdir('table/csv'):\n",
    "    shutil.rmtree('table/csv')\n",
    "    os.mkdir('table/csv')\n",
    "else:\n",
    "    os.mkdir('table/csv')\n",
    "\n",
    "#per ogni file .txt creo il corrispettivo in .csv nella cartella table/csv\n",
    "table_list = []\n",
    "pbar = tqdm(os.listdir('table/'), desc='converto .txt in .csv\\t')\n",
    "for filename in pbar:\n",
    "    if filename.endswith(\".txt\"):\n",
    "        #t.set_description(\"Bar desc (file %i)\" % i)\n",
    "        print(filename[:-4])\n",
    "        txt_to_csv(filename = 'table/' + filename[:-4],\n",
    "                   filedest = 'table/csv/' + filename[:-4])\n",
    "        \n",
    "        # creo una lista con i nomi delle tabelle da unire\n",
    "        if not filename[-5:-4].isdigit():\n",
    "            table_list.append(filename[:-4])\n",
    "\n",
    "# unisco i csv\n",
    "pbar = tqdm(table_list, desc='unisco le tabelle\\t')\n",
    "for table in pbar:\n",
    "    create_single_csv('table/', table)\n",
    "\n",
    "# elimino i file originali e tengo solo i .csv uniti\n",
    "pbar = tqdm(os.listdir('table/csv'), desc='elimino tab divise\\t')\n",
    "for filename in pbar:\n",
    "    if not filename.endswith('_all.csv'):\n",
    "        os.remove('table/csv/'+filename)\n",
    "        \n",
    "print(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00acd790",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'table/csv/TabLogFMS_DX_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-bff7d91b8167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'table/csv/TabLogFMS_DX_all.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DataTime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'table/csv/TabLogFMS_DX_all.csv'"
     ]
    }
   ],
   "source": [
    "create_single_csv('table/', 'TabLogFMS_DX')\n",
    "df = pd.read_csv ('table/csv/TabLogFMS_DX_all.csv', index_col='DataTime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef831b0",
   "metadata": {},
   "source": [
    "## Caricamento dati in modo manuale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "218fbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogFMS3_DX.csv\n",
      "TabLogFMS_DX.csv\n",
      "TabLogFMS4_DX.csv\n",
      "TabLogFMS2_DX.csv\n",
      "TabLogFMS_SX.csv\n",
      "TabLogFMS3_SX.csv\n",
      "TabLogFMS4_SX.csv\n",
      "TabLogFMS2_SX.csv\n",
      "TabLogPostTHS.csv\n",
      "TabLogPostTHS3.csv\n",
      "TabLogPostTHS2.csv\n",
      "TabLogPostTHS4.csv\n",
      "DiagnosisTabl3.csv\n",
      "DiagnosisTabl2.csv\n",
      "DiagnosisTable3.csv\n",
      "DiagnosisTable.csv\n",
      "DiagnosisTable4.csv\n",
      "DiagnosisTabl4.csv\n",
      "DiagnosisTable2.csv\n",
      "TabLogAntTHS4.csv\n",
      "TabLogAntTHS3.csv\n",
      "TabLogAntTHS.csv\n",
      "TabLogAntTHS2.csv\n",
      "DiagnTableBasaments2.csv\n",
      "DiagnTableBasaments3.csv\n",
      "DiagnTableBasaments4.csv\n",
      "DiagnTableBasaments.csv\n",
      "LONG_TERM_TEMP.csv\n",
      "TabLogAntTHS_all.csv\n",
      "DiagnTableBasaments_all.csv\n",
      "TabLogFMS_SX_all.csv\n",
      "LONG_TERM_TEMP_all.csv\n",
      "TabLogPostTHS_all.csv\n",
      "DiagnosisTabl_all.csv\n",
      "TabLogFMS_DX_all.csv\n",
      "TabLogTHS_all.csv\n"
     ]
    }
   ],
   "source": [
    "def CARICA_TABELLE_BRUTTO():\n",
    "\n",
    "    #--- carico tutti i file TabLogFMS_DX\n",
    "    dflist=[]\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if 'TabLogFMS' in file and '_DX' in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/TabLogFMS_DX_all.csv')    \n",
    "\n",
    "    #--- carico tutti i file TabLogFMS_SX\n",
    "    dflist=[]\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if 'TabLogFMS' in file and '_SX' in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/TabLogFMS_SX_all.csv')\n",
    "\n",
    "    #--- carico tutti i file TabLogPostTHS\n",
    "    dflist=[]\n",
    "    filename = 'TabLogPostTHS'\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if filename in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/' + filename + '_all.csv')\n",
    "\n",
    "    #--- carico tutti i file DiagnosisTabl\n",
    "    dflist=[]\n",
    "    filename = 'DiagnosisTabl'\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if filename in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/' + filename + '_all.csv')\n",
    "\n",
    "    #--- carico tutti i file TabLogAntTHS\n",
    "    dflist=[]\n",
    "    filename = 'TabLogAntTHS'\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if filename in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/' + filename + '_all.csv')\n",
    "\n",
    "    #--- carico tutti i file DiagnTableBasaments\n",
    "    dflist=[]\n",
    "    filename = 'DiagnTableBasaments'\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if filename in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/' + filename + '_all.csv')\n",
    "\n",
    "    #--- carico tutti i file LONG_TERM_TEMP\n",
    "    dflist=[]\n",
    "    filename = 'LONG_TERM_TEMP'\n",
    "    for file in os.listdir('table/csv'):\n",
    "        if filename in file and not '_all' in file:\n",
    "            print(file)\n",
    "            df = load_data('table/csv/' + file)\n",
    "            dflist.append(df)\n",
    "\n",
    "    data_all = pd.concat(dflist)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv('table/csv/' + filename + '_all.csv')\n",
    "\n",
    "# elimino i file originali e tengo solo i .csv uniti che carico in un dizionario di dataframe\n",
    "dataDict={}\n",
    "for filename in os.listdir('table/csv'):\n",
    "    if not filename.endswith('_all.csv'):\n",
    "        os.remove('table/csv/'+filename)\n",
    "    elif filename.endswith('_all.csv'):\n",
    "        print(filename)\n",
    "        df = pd.read_csv ('table/csv/'+filename, index_col='DataTime')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.resample('5T').mean()\n",
    "        dataDict[filename[:-4]] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fee11efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogAntTHS_all.csv\n",
      "TabLogFMS2_DX_all.csv\n",
      "DiagnTableBasaments_all.csv\n",
      "TabLogFMS_SX_all.csv\n",
      "DiagnosisTable_all.csv\n",
      "TabLogFMS2_SX_all.csv\n",
      "TabLogFMS4_SX_all.csv\n",
      "LONG_TERM_TEMP_all.csv\n",
      "TabLogFMS4_DX_all.csv\n",
      "TabLogFMS3_SX_all.csv\n",
      "TabLogPostTHS_all.csv\n",
      "TabLogFMS3_DX_all.csv\n",
      "TabLogFMS_DX_all.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Mach</th>\n",
       "      <th>t_HydrTa</th>\n",
       "      <th>t_TTlubr</th>\n",
       "      <th>t_TT_ab1</th>\n",
       "      <th>t_TT_ab2</th>\n",
       "      <th>t_HdStUp</th>\n",
       "      <th>t_HdStLw</th>\n",
       "      <th>t_Sfrnt1</th>\n",
       "      <th>t_Sfrnt2</th>\n",
       "      <th>t_Srear</th>\n",
       "      <th>t_Smotor</th>\n",
       "      <th>t_ReqDom</th>\n",
       "      <th>t_ExtDom</th>\n",
       "      <th>t_ProDom</th>\n",
       "      <th>t_Envir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-29 08:23:01</th>\n",
       "      <td>19.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 08:24:01</th>\n",
       "      <td>19.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 08:25:01</th>\n",
       "      <td>19.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 08:26:01</th>\n",
       "      <td>19.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 08:27:01</th>\n",
       "      <td>19.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     t_Mach  t_HydrTa  t_TTlubr  t_TT_ab1  t_TT_ab2  t_HdStUp  \\\n",
       "DataTime                                                                        \n",
       "2021-04-29 08:23:01    19.4      21.6      19.2      19.2      19.3      20.7   \n",
       "2021-04-29 08:24:01    19.4      21.6      19.2      19.2      19.3      20.7   \n",
       "2021-04-29 08:25:01    19.4      21.6      19.2      19.2      19.3      20.7   \n",
       "2021-04-29 08:26:01    19.4      21.6      19.2      19.2      19.3      20.7   \n",
       "2021-04-29 08:27:01    19.4      21.6      19.2      19.2      19.3      20.7   \n",
       "\n",
       "                     t_HdStLw  t_Sfrnt1  t_Sfrnt2  t_Srear  t_Smotor  \\\n",
       "DataTime                                                               \n",
       "2021-04-29 08:23:01      20.4      23.0      23.3     23.6      25.6   \n",
       "2021-04-29 08:24:01      20.4      23.0      23.3     23.6      25.0   \n",
       "2021-04-29 08:25:01      20.4      22.9      23.2     23.6      25.6   \n",
       "2021-04-29 08:26:01      20.4      23.3      23.3     23.6      26.0   \n",
       "2021-04-29 08:27:01      20.4      23.6      23.5     23.6      26.0   \n",
       "\n",
       "                     t_ReqDom  t_ExtDom  t_ProDom  t_Envir  \n",
       "DataTime                                                    \n",
       "2021-04-29 08:23:01        20        20        20     21.4  \n",
       "2021-04-29 08:24:01        20        20        20     21.4  \n",
       "2021-04-29 08:25:01        20        20        20     21.4  \n",
       "2021-04-29 08:26:01        20        20        20     21.4  \n",
       "2021-04-29 08:27:01        20        20        20     21.4  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDict={}\n",
    "for filename in os.listdir('table/csv'):\n",
    "    print(filename)\n",
    "    df = pd.read_csv ('table/csv/'+filename, index_col='DataTime')\n",
    "    dataDict[filename[:-4]] = df\n",
    "\n",
    "\n",
    "dataDict['TabLogAntTHS_all'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
