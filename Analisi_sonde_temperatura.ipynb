{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eaa6465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1787f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Funzione per trasformare i dati in CSV\n",
    "Lo script prende in input un file .txt con il parametro 'rb' quindi in lettura in formato bytecode che vuol dire che dovrà essere decodificato.\n",
    "Per prima cosa si scorre fino alla riga che inizia con 'NR' perché i dati iniziano da li, quando la trovo imposto flag_data a 1 che serve a dirmi che da li in poi dovrò salvare le righe.\n",
    "Cerco la prima riga che inizia con '0' e la salto settando firsr_row a 1.\n",
    "Quando sia data_flag che first_row sono a 1 allora inizio a salvare le righe.\n",
    "\n",
    "Per salvare le righe:\n",
    "* prima le decodifico con .decode()\n",
    "* poi le divido con .split() che se usato senza parametri splitta la stringa in base agli spazi\n",
    "* unisco i valori delle ultime due colonne perché fanno entrambi riferimento alla data\n",
    "* elimino l'ultima riga perché l'ho unita alla penultima\n",
    "* faccio un append della riga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9256882",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def txt_to_csv(filename, filedest):\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(filedest + '.csv'):\n",
    "        os.remove(filedest + '.csv')\n",
    "        \n",
    "    file1 = open(filename + '.txt', \"rb\")\n",
    "    file_csv = open(filedest + '.csv', 'w+', newline ='')\n",
    "\n",
    "    count = 0\n",
    "    flag_data = 0\n",
    "\n",
    "    with file_csv:\n",
    "        for line in file1:\n",
    "\n",
    "            if b'\\xb0C' in line:     # se trovo il carattere °C lo ignoro\n",
    "                pass\n",
    "            else:\n",
    "                line = line.decode() # altrimenti decodifico la riga\n",
    "\n",
    "                # cerco la riga con i nomi della tabella\n",
    "                if line.startswith('NR'):\n",
    "                    flag_data = 1                  # quando trovo i nomi delle colonne imposto flag_data = 1\n",
    "                    table_names = line.split()     # divido i nomi delle colonne      \n",
    "                    table_names.remove('LastLine') # elimino 'LastLine' che fa riferimento ad un singolo dato duplicato\n",
    "                    #for item in table_names: print(item)\n",
    "                    write = csv.writer(file_csv)  \n",
    "                    write.writerow(table_names)\n",
    "\n",
    "                # Se sono arrivato alla tabella ma la riga inizia con 0 la salto\n",
    "                elif flag_data == 1 and line.startswith('0'):\n",
    "                    pass\n",
    "\n",
    "                # Se sono arrivato alla tabella (flag_data == 1) e non sono alla prima riga\n",
    "                # inizio a salvare i dati\n",
    "                elif flag_data == 1:\n",
    "                    row = line.split()\n",
    "\n",
    "                    if not line.startswith('[END]') and len(row) == len(table_names)+1: # le righe con meno di 25 elementi hanno dati mancanti\n",
    "                        row[-2] = str(row[-2]) + ' ' + str(row[-1]) # unisco l'ora col giorno\n",
    "                        del row[-1] # elimino la colonna con i giorni\n",
    "                        write = csv.writer(file_csv)\n",
    "                        write.writerow(row)\n",
    "                        count = count+1      # aggiorno il contatore delle righe\n",
    "\n",
    "    #print(str(count) + ' righe salvate.')\n",
    "\n",
    "#txt_to_csv('Tabelle_omv/TabLogAntTHS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da9adf",
   "metadata": {},
   "source": [
    "Per convertire tutti i file da txt a csv mi basta iterare all'interno della cartella e passare ogni file alla funzione txt_to_csv che prende in input il nome del file da convertire e il percorso di destinazione del file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e353f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for filename in os.listdir('Tabelle_omv/'):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        print(filename[:-4])\n",
    "        txt_to_csv(filename = 'Tabelle_omv/' + filename[:-4],\n",
    "                   filedest = 'Tabelle_omv/csv/' + filename[:-4])\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b1676",
   "metadata": {},
   "source": [
    "## Funzione per caricare il CSV in un DataFrame\n",
    "La funzione prende in input il nome del file .csv da caricare, converte la colonna DataTime in datetime e la imposta come indice del dataframe. Controlla se il dataframe è ordinato e se non lo è lo riordina. Elimina la colonna NR. Restituisce il dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d7481f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    #column_subset = ['t_Mach',   't_HydrTa', 't_TTlubr', 't_TT_ab1', \n",
    "                     #'t_TT_ab2', 't_HdStUp', 't_HdStLw', 't_Sfrnt1', \n",
    "                     #'t_Sfrnt2', 't_Srear',  't_Smotor', 'DataTime']\n",
    "\n",
    "    df = pd.read_csv (file,\n",
    "                      #usecols=column_subset,\n",
    "                      index_col=False)\n",
    "\n",
    "    df['DataTime'] = pd.to_datetime(df['DataTime'], format='%H:%M:%S %d.%m.%Y')\n",
    "    \n",
    "    df.set_index('DataTime', drop = True, inplace=True)\n",
    "    \n",
    "    if not df.index.is_monotonic:\n",
    "        df.sort_index(inplace = True)\n",
    "    \n",
    "    df.drop('NR', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d85f99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for filename in os.listdir('Tabelle_omv/csv/'):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        print(filename)\n",
    "        data = load_data('Tabelle_omv/csv/' + filename)\n",
    "        data.info()\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0ae0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path = 'Tabelle_omv/csv/'\n",
    "\n",
    "data1 = load_data(path + 'TabLogAntTHS.csv')\n",
    "data2 = load_data(path + 'TabLogAntTHS2.csv')\n",
    "data3 = load_data(path + 'TabLogAntTHS3.csv')\n",
    "data4 = load_data(path + 'TabLogAntTHS4.csv')\n",
    "\n",
    "data_all = pd.concat([data1, data2, data3, data4])\n",
    "print(data_all.index.is_monotonic)\n",
    "data_all.sort_index(inplace = True)\n",
    "print(data_all.index.is_monotonic)\n",
    "\n",
    "data_all.info()\n",
    "print(pd.date_range(start = '2020-02-24 17:55:01', end = '2020-05-06 02:55:01' ).difference(data_all.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033571d",
   "metadata": {},
   "source": [
    "## Processo per caricare tutti i file dello stesso tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e457b19a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogPostTHS3\n",
      "TabLogPostTHS4\n",
      "TabLogPostTHS\n",
      "TabLogPostTHS2\n",
      "DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "path = 'Tabelle_omv/'\n",
    "data_file = 'TabLogPostTHS'\n",
    "data_list=[]\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".txt\") and data_file in filename: \n",
    "        print(filename[:-4])\n",
    "        txt_to_csv(filename = path + filename[:-4],\n",
    "                   filedest = path + 'csv/' + filename[:-4])\n",
    "        \n",
    "        data = load_data(path + 'csv/' + filename[:-4] + '.csv')\n",
    "        data_list.append(data)\n",
    "        \n",
    "data_all = pd.concat(data_list)\n",
    "data_all.sort_index(inplace = True)\n",
    "\n",
    "print(pd.date_range(start = '2020-02-21 22:50:01', end = '2020-04-02 08:52:01' ).difference(data_all.index))\n",
    "\n",
    "#data_all = data_all.loc['2020-04-02 01:05:00':'2020-05-04 23:05:00']\n",
    "#data_all.drop('OpMode', axis=1, inplace=True)\n",
    "#data_all = data_all.resample('1T').mean()\n",
    "#data_all = data_all.round(2)\n",
    "\n",
    "data_all.info()\n",
    "#print(pd.date_range(start = '2020-02-21 22:00:00', end = '2020-04-02 08:00:00' ).difference(data_all.index))\n",
    "#data_all.loc['2020-03-05 11:00:00':'2020-03-05 14:00:00']\n",
    "#fig = px.line(data_all)\n",
    "#fig.show()\n",
    "\n",
    "data_all.to_csv(data_file + '_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149ee15",
   "metadata": {},
   "source": [
    "### Funzione che carica tutte le tabelle dello stesso tipo e le riunisce nello stesso df\n",
    "Per velocizzare il caricamento dei dati unisco tutte le tabelle in un unico file così devo caricare solo quello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7509915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLogPostTHS3\n",
      "TabLogPostTHS4\n",
      "TabLogPostTHS\n",
      "TabLogPostTHS2\n",
      "DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "def create_single_csv(path_folder, tab_name):\n",
    "    data_list=[]\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\") and data_file in filename: \n",
    "            print(filename[:-4])\n",
    "            txt_to_csv(filename = path + filename[:-4],\n",
    "                       filedest = path + 'csv/' + filename[:-4])\n",
    "\n",
    "            data = load_data(path + 'csv/' + filename[:-4] + '.csv')\n",
    "            data_list.append(data)\n",
    "\n",
    "    data_all = pd.concat(data_list)\n",
    "    data_all.sort_index(inplace = True)\n",
    "    data_all.to_csv(data_file + '_all')\n",
    "\n",
    "#------- MAIN\n",
    "path = 'Tabelle_omv/'\n",
    "data_file = 'TabLogPostTHS'\n",
    "\n",
    "create_single_csv(path, data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
